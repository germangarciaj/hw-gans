{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Um1J0VRVN5b7"
   },
   "source": [
    "<h1><center> EL7006 - Tarea Nº3 <br /> Generative Models: Generative Adversarial Networks <br/> </center></h1>\n",
    "<h3><center>Profesor: Pablo Estévez <br />\n",
    "Profesor Auxiliar: Nicolás Astorga <br />\n",
    "Ayudantes: Germán García, Nicolás Tapia <br />\n",
    "<h3><center>Semestre: Primavera 2020 </center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><u>Parte Teórica</u></center></h1>\n",
    "\n",
    "Responda las siguientes preguntas respecto a GANs: \n",
    "\n",
    "Considerando el modelo de GAN original\n",
    "\n",
    "1. Explique el problema de <i>vanishing gradients</i> y cómo se soluciona. Argumente matemáticamente.\n",
    "\n",
    "2. Si durante el juego entre Generador y Discriminador, se alcanzara el deseado equilibrio de Nash. Cual sería la salida del Discriminador ? Cuál Sería el valor de su función de <i>loss </i> ? \n",
    "\n",
    "3. Por qué la evaluación de GANs es un problema desafiante ? Es posible utilizar el Discriminador para la evaluación de modelos ? \n",
    "\n",
    "<font size=3 color=red> <b>Respuesta: </b></font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><u>Parte Práctica </u></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este parte, usted debe implementar, entrenar distintos modelos de GANs para generación de imágenes de MNIST. Además deberá comparar el desempeño de estos modelos según la métrica de evaluación solicitada. \n",
    "\n",
    "\n",
    "<h2>Preliminares: Google Colab</h2>\n",
    "\n",
    "Para evitar limitaciones de hardware, ejecute este notebook en Google Colab con GPU. Para ello siga estos pasos:\n",
    "\n",
    "- Suba este notebook a su cuenta de Google Drive.\n",
    "- Abra el notebook. Se hará automáticamente en Google Colab.\n",
    "- En el menú \"Entorno de ejecución\", seleccione \"Cambiar tipo de entorno de ejecución\" y en \"Acelerador por hardware\" seleccione GPU.\n",
    "\n",
    "<h2>Preliminares: PyTorch</h2>\n",
    "\n",
    "Por simplicidad, en esta tarea se utilizará PyTorch. Se entrega una estructura general del código a implementar, con el objetivo de no requerir conocimientos profundos del framework utilizado. Además, se entregan <i> unit tests </i> que permitirán guiar su trabajo a través de los módulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deep Convolutional GAN (DCGAN) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, usted deberá implementar una [DCGAN](https://arxiv.org/pdf/1511.06434v1.pdf), el primer modelo de GAN convolucional desarollado en el 2015. Alguna de las características de la DCGAN son mencionadas a continuación: \n",
    "\n",
    "*   Usa convoluciones sin capas de pooling\n",
    "*   Usa BatchNormalization tanto en el Generador como en el Discriminador\n",
    "*   No usa capas <i> Fully Connected </i>\n",
    "*   Usa activaciones ReLU en el Generador, salvo en la última capa donde usa Tanh.\n",
    "*   Usa activaciones LeakyReLU en el Discriminador, salvo en la última capa donde no usa activación\n",
    "\n",
    "A continuación se importan los paquetes a utilizar y se define una función útil para visualizar las imágenes generadas por la GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "torch.manual_seed(0); # Set for testing purposes, please do not change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional, if you have multiple devices and just want to use one. \n",
    "# i_device = 1\n",
    "# device = 'cuda:{0}'.format(i_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), save=False, name=None, epoch=None):\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
    "    \n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    plt.axis('off')\n",
    "    if save:\n",
    "        plt.savefig('{}_epoch_{}.png'.format(name, epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Bloque del Generador </h3>\n",
    "\n",
    "Para comenzar, deberá implementar los bloques que componen el Generador.\n",
    "Debido a que la función de activación varía según la capa, se deberá considerar esto al momento de la creación del bloque.\n",
    "\n",
    "La estructura de cada bloque deberá ser la siguiente: \n",
    "*   Una capa deconvolucional, utilizando los parámetros dados\n",
    "*   Una capa de batchnorm, salvo en la última capa\n",
    "*   Una activación ReLU después de cada batchnorm\n",
    "*   Una activacion Tanh, sólo para la última capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gen_block(input_channels, output_channels, kernel_size=3, stride=2, final_layer=False):\n",
    "    if not final_layer:\n",
    "        return nn.Sequential(\n",
    "        ### YOUR CODE HERE ###\n",
    "        )\n",
    "    else:\n",
    "        return nn.Sequential(\n",
    "        ### YOUR CODE HERE ###\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    return torch.randn(n_samples, z_dim, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Generador</h2>\n",
    "\n",
    "Ahora construya un Generador formado por 4 bloques, con las siguientes especificaciones:\n",
    "\n",
    "    1.-block: z_dim          -> hidden_dim * 4 , kernel_size=3, stride=2\n",
    "    2.-block: hidden_dim * 4 -> hidden_dim * 2 , kernel_size=4, stride=1\n",
    "    3.-block: hidden_dim * 2 -> hidden_dim     , kernel_size=3, stride=2\n",
    "    4.-block: hidden_dim     -> im_chan        , kernel_size=4, stride=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=10, im_chan=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "        ### YOUR CODE HERE ###\n",
    "        )\n",
    "\n",
    "    def unsqueeze_noise(self, noise):\n",
    "        return noise.view(len(noise), self.z_dim, 1, 1)\n",
    "\n",
    "    def forward(self, noise):\n",
    "        x = self.unsqueeze_noise(noise)\n",
    "        return self.gen(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tests Generador </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()\n",
    "num_test = 100\n",
    "\n",
    "# Test the hidden block\n",
    "test_hidden_noise = get_noise(num_test, gen.z_dim)\n",
    "test_hidden_block = make_gen_block(10, 20, kernel_size=4, stride=1)\n",
    "test_uns_noise = gen.unsqueeze_noise(test_hidden_noise)\n",
    "hidden_output = test_hidden_block(test_uns_noise)\n",
    "\n",
    "# Check that it works with other strides\n",
    "test_hidden_block_stride = make_gen_block(20, 20, kernel_size=4, stride=2)\n",
    "\n",
    "test_final_noise = get_noise(num_test, gen.z_dim) * 20\n",
    "test_final_block = make_gen_block(10, 20, final_layer=True)\n",
    "test_final_uns_noise = gen.unsqueeze_noise(test_final_noise)\n",
    "final_output = test_final_block(test_final_uns_noise)\n",
    "\n",
    "# Test the whole thing\n",
    "test_gen_noise = get_noise(num_test, gen.z_dim)\n",
    "test_uns_gen_noise = gen.unsqueeze_noise(test_gen_noise)\n",
    "gen_output = gen(test_uns_gen_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TESTS\n",
    "assert tuple(hidden_output.shape) == (num_test, 20, 4, 4)\n",
    "assert hidden_output.max() > 1\n",
    "assert hidden_output.min() == 0\n",
    "assert hidden_output.std() > 0.2\n",
    "assert hidden_output.std() < 1\n",
    "assert hidden_output.std() > 0.5\n",
    "\n",
    "assert tuple(test_hidden_block_stride(hidden_output).shape) == (num_test, 20, 10, 10)\n",
    "\n",
    "assert final_output.max().item() == 1\n",
    "assert final_output.min().item() == -1\n",
    "\n",
    "assert tuple(gen_output.shape) == (num_test, 1, 28, 28)\n",
    "assert gen_output.std() > 0.5\n",
    "assert gen_output.std() < 0.8\n",
    "print(\"Well done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Bloque del discriminador</h3>\n",
    "\n",
    "Procederemos a implementar un bloque para el discriminador.\n",
    "La estructura de cada bloque deberá ser la siguiente: \n",
    "\n",
    "*    Una capa convolucional, utilizando los parámetros dados\n",
    "*    Una capa de batchnorm, excepto por la última capa\n",
    "*    Una activacion LeakyReLU de pendiente 0.2, sólo después de las capas de batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_disc_block(input_channels, output_channels, kernel_size=4, stride=2, final_layer=False):     \n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "            ### YOUR CODE HERE ###\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "            ### YOUR CODE HERE ###\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Discriminador </h2>\n",
    "\n",
    "Ahora construya un Discriminador formado por 3 bloques, con las siguientes especificaciones:\n",
    "\n",
    "    1.-block: im_chan        -> hidden_dim     , kernel_size=4, stride=2\n",
    "    2.-block: hidden_dim     -> hidden_dim * 2 , kernel_size=4, stride=2\n",
    "    3.-block: hidden_dim * 2 -> 1              , kernel_size=4, stride=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, im_chan=1, hidden_dim=16):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "        ### YOUR CODE HERE ###\n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        disc_pred = self.disc(image)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Test Discriminador </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 100\n",
    "\n",
    "gen = Generator()\n",
    "disc = Discriminator()\n",
    "test_images = gen(get_noise(num_test, gen.z_dim))\n",
    "\n",
    "# Test the hidden block\n",
    "test_hidden_block = make_disc_block(1, 5, kernel_size=6, stride=3)\n",
    "hidden_output = test_hidden_block(test_images)\n",
    "\n",
    "# Test the final block\n",
    "test_final_block = make_disc_block(1, 10, kernel_size=2, stride=5, final_layer=True)\n",
    "final_output = test_final_block(test_images)\n",
    "\n",
    "# Test the whole thing:\n",
    "disc_output = disc(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIT TESTS\n",
    "# Test the hidden block\n",
    "assert tuple(hidden_output.shape) == (num_test, 5, 8, 8)\n",
    "assert -hidden_output.min() / hidden_output.max() > 0.15\n",
    "assert -hidden_output.min() / hidden_output.max() < 0.25\n",
    "assert hidden_output.std() > 0.5\n",
    "assert hidden_output.std() < 1\n",
    "\n",
    "# Test the final block\n",
    "assert tuple(final_output.shape) == (num_test, 10, 6, 6)\n",
    "assert final_output.max() > 1.0\n",
    "assert final_output.min() < -1.0\n",
    "assert final_output.std() > 0.3\n",
    "assert final_output.std() < 0.6\n",
    "\n",
    "# Test the whole thing:\n",
    "\n",
    "assert tuple(disc_output.shape) == (num_test, 1)\n",
    "assert disc_output.std() > 0.25\n",
    "assert disc_output.std() < 0.5\n",
    "print(\"Well done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se definen los parámetros de entrenamiento a utlizar, y una funcion de utilidad para la inicialización de los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the training parameters\n",
    "z_dim = 64\n",
    "display_step = 500\n",
    "batch_size = 128\n",
    "lr = 0.0002\n",
    "beta_1 = 0.5 \n",
    "beta_2 = 0.999\n",
    "# device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    MNIST('.', download=True, transform=transform),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "disc = Discriminator().to(device) \n",
    "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Funciones de Loss</h3>\n",
    "\n",
    "Implemente los métodos `get_gen_loss` y `get_disc_loss` que calculen las funciones de <i> loss </i> del modelo original de GAN, con la solución al problema de <i> vanishing gradients </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_entropy = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def get_gen_loss(disc_fake_pred):\n",
    "    ### YOUR CODE HERE ###\n",
    "    gen_loss = None\n",
    "    return gen_loss\n",
    "\n",
    "def get_disc_loss(disc_fake_pred, disc_real_pred):\n",
    "    ### YOUR CODE HERE ###\n",
    "    disc_loss = None\n",
    "    return disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Entrenamiento DCGAN </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se proporciona el código para el entrenamiento de la DCGAN, utilizando los métodos anteriormente implementados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "cur_step = 0\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n",
    "for epoch in range(n_epochs):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        # Update discriminator\n",
    "        disc_opt.zero_grad()\n",
    "        fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake = gen(fake_noise)\n",
    "        disc_fake_pred = disc(fake.detach())\n",
    "        disc_real_pred = disc(real)\n",
    "        disc_loss = get_disc_loss(disc_fake_pred, disc_real_pred)\n",
    "\n",
    "        mean_discriminator_loss += disc_loss.item() / display_step\n",
    "        # Update gradients\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        # Update optimizer\n",
    "        disc_opt.step()\n",
    "\n",
    "        # Update generator \n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        disc_fake_pred = disc(fake_2)\n",
    "        gen_loss = get_gen_loss(disc_fake_pred)\n",
    "        gen_loss.backward()\n",
    "        gen_opt.step()\n",
    "        mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "        # Visualization code\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
    "            display.clear_output(wait=True)\n",
    "            show_tensor_images(fake, save=True, epoch=epoch, name='vanilla_dc_gan')\n",
    "            show_tensor_images(real)\n",
    "            mean_generator_loss = 0\n",
    "            mean_discriminator_loss = 0\n",
    "        cur_step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'dcgan'\n",
    "# torch.save(gen.state_dict(), name)\n",
    "# gen.load_state_dict(torch.load(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Wasserstein GAN with Gradient Penalty (WGAN-GP) </h2>\n",
    "\n",
    "A continuación, deberá implementar una WGAN-GP que resuelve alguno de los problemas de estabilidad en el entrenamiento de GANs. <br>En este modelo, se modifica la loss estándar por la W-loss correspondiente a una distancia de Wasserstein, y se agrega un término de penalización por gradiente que ayuda a prevenir el problema del <i>mode collapse </i>\n",
    "\n",
    "Debido a que los cambios del modelo son hechos a la loss, es posible utilizar el mismo Generador y Discriminador de la DCGAN. <br>En esta ocasión, el discriminador pasará a llamarse crítico, por su función de entregar valores reales a cada uno de los ejemplos presentados, en vez de clasificarlos como real/falso.\n",
    "\n",
    "Comenzaremos por definir una función de utilidad para poder hacer seguimiento de los valores del gradiente, e inicializar nuevamente los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grad_hook():\n",
    "    grads = []\n",
    "    def grad_hook(m):\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            grads.append(m.weight.grad)\n",
    "    return grads, grad_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352,
     "referenced_widgets": [
      "b16f592cc3964cccb48ea8247a83d93c",
      "1d0d36a15ed24a11a64631880986cbe2",
      "b7291a08accb4c978c9c6f368e0958bb",
      "b8115cdd58e64d179e683903ad468a66",
      "25ac91c871744f10b4c6e4f1099fecfa",
      "ba6a57ef686a4e128e0ac5b61ec7bbb0",
      "3f8115b26eb744a9a66dd5952a76e486",
      "3a44d4d196c940e186f2ad7c978af58e",
      "c02e809ef8bd41c39c6685fc9ce9e97e",
      "be0abdaac7744d3a915ea6f710f482f0",
      "b426f0363f5e4bbfb442b16b1482e98a",
      "2abda2d9d9ca4970b528e2e29f12f4b4",
      "c861f7f9c6db4e60b9e9cc3571c1d558",
      "1fb9f3f27a7d4784b944479f8724ce8b",
      "61d57a6747f542779a1fa9903d63b270",
      "a34a69313e64475bbea18f55d3d570c7",
      "bd82c2e94e224c1ca71e9bfee2facf16",
      "b11c1e9c1c864c87ade7897e66108551",
      "f3138380792542a3aa7a5ee7fd8fca44",
      "46356cd2605a4f97b60e774df34f4e4b",
      "44b8f12ebf6d4928b8ec5939d2a4f43f",
      "90e46596d5034e058638960da71cd3de",
      "f043c3530998460eb8a540f673994e4e",
      "4311158e895448ebb68efe079896f4b5",
      "9041af49322f4246af43f1ed7579063b",
      "d9c11e9a1d6e4327bde7c917bc0db171",
      "b503a11497f64a63961287665024a499",
      "7d5c4bbce6ec4e6bb61a415ad968342d",
      "bdb5a2d8e9ac4f9db45a6c4002b22c2d",
      "ce2757c985e14276bf7222c020c473a4",
      "0c164c68cf6849f89194d2d5e0ed4b07",
      "252af3366dab40068dbbe9845f098560"
     ]
    },
    "colab_type": "code",
    "id": "IFLQ039u-qdu",
    "outputId": "2969e573-0b53-49e0-b1e9-ac6058d5d6b2"
   },
   "outputs": [],
   "source": [
    "# New training parameters\n",
    "n_epochs = 100\n",
    "display_step = 50\n",
    "c_lambda = 10\n",
    "crit_repeats = 5\n",
    "# device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sDFRZ8tg_Y57",
    "outputId": "d759a7d3-48e9-450b-81a0-dc5cfe406a8d"
   },
   "outputs": [],
   "source": [
    "gen = Generator(z_dim).to(device)\n",
    "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "crit = Discriminator().to(device) \n",
    "crit_opt = torch.optim.Adam(crit.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "crit = crit.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFEi5BhVX5-P"
   },
   "source": [
    "## Gradient Penalty\n",
    "\n",
    "La loss del discriminador requerirá de un termino adicional de penalización.\n",
    "Este corresponde a \n",
    "$ \\displaystyle \\mathop{\\mathbb{E }}_{\\hat{\\mathbf{x}}}[ (\\lVert \\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}}) \\rVert - 1)^2 ]$ \n",
    "\n",
    "Para su cálculo, usted deberá:\n",
    "   - Calcular $\\hat{x}$, un promedio ponderado entre imágenes reales y falsas: $\\hat{\\mathbf{x}} = \\epsilon \\mathbf{x} + (1-\\epsilon)G(\\mathbf{z})$, siendo $\\epsilon$ escogido aleatoriamente entre 0 y 1\n",
    "   - Calcular el <i> score </i> entregado por el crítico a $\\hat{x}$\n",
    "   - Calcular el gradiente.\n",
    "   - Computar el termino de gradient penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tn4dkXnNtcv6"
   },
   "outputs": [],
   "source": [
    "def get_gradient(crit_model, real_images, fake_images, epsilon):\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    mixed_images = None\n",
    "    mixed_scores = None\n",
    "    \n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        ### YOUR CODE HERE ###\n",
    "        inputs=None,\n",
    "        outputs=None,\n",
    "        # These other parameters have to do with the pytorch autograd engine works\n",
    "        grad_outputs=torch.ones_like(mixed_scores), \n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8av4TtbMtkTq"
   },
   "outputs": [],
   "source": [
    "def test_get_gradient(image_shape):\n",
    "    real = torch.randn(*image_shape, device=device) + 1\n",
    "    fake = torch.randn(*image_shape, device=device) - 1\n",
    "    epsilon_shape = [1 for _ in image_shape]\n",
    "    epsilon_shape[0] = image_shape[0]\n",
    "    epsilon = torch.rand(epsilon_shape, device=device).requires_grad_()\n",
    "    gradient = get_gradient(crit, real, fake, epsilon)\n",
    "    assert tuple(gradient.shape) == image_shape\n",
    "    assert gradient.max() > 0\n",
    "    assert gradient.min() < 0\n",
    "    return gradient\n",
    "\n",
    "gradient = test_get_gradient((256, 1, 28, 28))\n",
    "print(\"Well done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z5PMRrMpRUK-"
   },
   "source": [
    "Ahora, implemente el método `gradient_penalty` para calcular el término completo de penalización de gradiente, dado los gradientes\n",
    "\n",
    "*    No olvide computar la esperanza \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPwBH83IzCpS"
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(gradient):\n",
    "    \n",
    "    # Flatten the gradients so that each row captures one image\n",
    "    gradient = gradient.view(len(gradient), -1)\n",
    "\n",
    "    ### YOUR CODE HERE ###\n",
    "    # Calculate the magnitude of every row\n",
    "    gradient_norm = None\n",
    "    \n",
    "    # Penalize the mean squared distance of the gradient norms from 1\n",
    "    penalty = None\n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahPfGMA2zABQ"
   },
   "outputs": [],
   "source": [
    "# UNIT TEST\n",
    "def test_gradient_penalty(image_shape):\n",
    "    bad_gradient = torch.zeros(*image_shape)\n",
    "    bad_gradient_penalty = gradient_penalty(bad_gradient)\n",
    "    assert torch.isclose(bad_gradient_penalty, torch.tensor(1.))\n",
    "\n",
    "    image_size = torch.prod(torch.Tensor(image_shape[1:]))\n",
    "    good_gradient = torch.ones(*image_shape) / torch.sqrt(image_size)\n",
    "    good_gradient_penalty = gradient_penalty(good_gradient)\n",
    "    assert torch.isclose(good_gradient_penalty, torch.tensor(0.))\n",
    "\n",
    "    random_gradient = test_get_gradient(image_shape)\n",
    "    random_gradient_penalty = gradient_penalty(random_gradient)\n",
    "    assert torch.abs(random_gradient_penalty - 1) < 0.1\n",
    "\n",
    "test_gradient_penalty((256, 1, 28, 28))\n",
    "print(\"Well done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sob-u9Z1X9sb"
   },
   "source": [
    "## Losses\n",
    "\n",
    "En una WGAN-GP, el discriminador se utiliza para aproximar la distancia de Wasserstein, la cual está dada por la expresion:  \n",
    "\n",
    "$\\mathbb{W} \\approx \\displaystyle \\mathop{\\mathbb{E }}_{{\\mathbf{x}}}[D(\\mathbf{x})] - \\displaystyle \\mathop{\\mathbb{E }}_{\\mathbf{x}'=G(\\mathbf{z})} [D(G(\\mathbf{z}))] + \\displaystyle \\mathop{\\mathbb{E }}_{\\hat{\\mathbf{x}}} \\lambda (\\lVert \\nabla_{\\hat{\\mathbf{x}}} D(\\hat{\\mathbf{x}}) \\rVert - 1)^2 $\n",
    "\n",
    "Usted deberá implementar los métodos `get_gen_wloss` y `get_crit_wloss` que devuelvan $L_{D}$ y $L_{G}$, los cuales serán utilizados para maximizar y minimizar $\\mathbb{W}$, respectivamente. \n",
    "\n",
    "Obs: Notar que $L_G$ sólo debería tener un término"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnJFs-qkMCA-"
   },
   "outputs": [],
   "source": [
    "def get_gen_wloss(crit_fake_pred):\n",
    "    ### YOUR CODE HERE ###\n",
    "    gen_loss = None\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fYVqG8bR6Hfg"
   },
   "outputs": [],
   "source": [
    "# UNIT TEST\n",
    "assert torch.isclose(\n",
    "    get_gen_wloss(torch.tensor(1.)), torch.tensor(-1.0)\n",
    ")\n",
    "\n",
    "assert torch.isclose(\n",
    "    get_gen_lwoss(torch.rand(10000)), torch.tensor(-0.5), 0.05\n",
    ")\n",
    "\n",
    "print(\"Well done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-jvbz1zDMTdu"
   },
   "outputs": [],
   "source": [
    "def get_crit_wloss(crit_fake_pred, crit_real_pred, gp, c_lambda):\n",
    "    ### YOUR CODE HERE ###\n",
    "    crit_loss = None\n",
    "    return crit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxZey6fc5luf"
   },
   "outputs": [],
   "source": [
    "# UNIT TEST\n",
    "assert torch.isclose(\n",
    "    get_crit_wloss(torch.tensor(1.), torch.tensor(2.), torch.tensor(3.), 0.1),\n",
    "    torch.tensor(-0.7)\n",
    ")\n",
    "assert torch.isclose(\n",
    "    get_crit_wloss(torch.tensor(20.), torch.tensor(-20.), torch.tensor(2.), 10),\n",
    "    torch.tensor(60.)\n",
    ")\n",
    "\n",
    "print(\"Well done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_x5wu7rUMlnZ"
   },
   "source": [
    "## Entrenamiento WGAN-GP\n",
    "\n",
    "Usted notará que, aún corriendo en GPU, el entrenamiento será notoriamente más lento. Ƥor que ? <br>\n",
    "<font size=3 color=red> <b>Respuesta: </b></font>     \n",
    "\n",
    "Además, notar que en el entrenamiento, se realizan varias actualizaiciones del critico por actualizaciones del generador para intentar compensar por la regularizacion aplicada, y que el generador no gane fácilmente el juego. \n",
    "\n",
    "Finalmente, si bien la WGAN-GP podría no ser mejor en cuanto calidad de imagenes generadas, mejora significativamente la estabilidad del entrenamiento y evita el <i> mode collapse </i>. Por esto, debería poder entrenar una WGANGP por muchas épocas sin sufrir de este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXptQZcwrBrq"
   },
   "outputs": [],
   "source": [
    "cur_step = 0\n",
    "generator_losses = []\n",
    "critic_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    for real, _ in tqdm(dataloader):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\n",
    "\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "            # Update critic\n",
    "            crit_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            crit_fake_pred = crit(fake.detach())\n",
    "            crit_real_pred = crit(real)\n",
    "\n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "            gradient = get_gradient(crit, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            crit_loss = get_crit_wloss(crit_fake_pred, crit_real_pred, gp, c_lambda)\n",
    "\n",
    "            mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "            # Update gradients\n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            # Update optimizer\n",
    "            crit_opt.step()\n",
    "        critic_losses += [mean_iteration_critic_loss]\n",
    "\n",
    "        # Update generator\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        crit_fake_pred = crit(fake_2)\n",
    "        \n",
    "        gen_loss = get_gen_wloss(crit_fake_pred)\n",
    "        gen_loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        gen_opt.step()\n",
    "\n",
    "        generator_losses += [gen_loss.item()]\n",
    "\n",
    "        # Visualization code\n",
    "        if cur_step % display_step == 0 and cur_step > 0:\n",
    "            display.clear_output(wait=True)\n",
    "            gen_mean = sum(generator_losses[-display_step:]) / display_step\n",
    "            crit_mean = sum(critic_losses[-display_step:]) / display_step\n",
    "            print(f\"Step {cur_step}: Generator loss: {gen_mean}, critic loss: {crit_mean}\")\n",
    "            show_tensor_images(fake, save=True, name='wgangp')\n",
    "            show_tensor_images(real)\n",
    "            step_bins = 20\n",
    "            num_examples = (len(generator_losses) // step_bins) * step_bins\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(generator_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Generator Loss\"\n",
    "            )\n",
    "            plt.plot(\n",
    "                range(num_examples // step_bins), \n",
    "                torch.Tensor(critic_losses[:num_examples]).view(-1, step_bins).mean(1),\n",
    "                label=\"Critic Loss\"\n",
    "            )\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        cur_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'wgangp'\n",
    "# torch.save(gen.state_dict(), name)\n",
    "# gen.load_state_dict(torch.load(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluación : Fréchet Inception Distance </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "filename = 'inception_v3_google-1a9a5a14.pth'\n",
    "url = 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    wget.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3\n",
    "\n",
    "# This may take a while\n",
    "inception_model = inception_v3(pretrained=False)\n",
    "inception_model.load_state_dict(torch.load(filename))\n",
    "inception_model.to(device)\n",
    "inception_model = inception_model.eval() # Evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uf3kci9d2ROC"
   },
   "source": [
    "**Formula**\n",
    "\n",
    "Basado en el paper \"[The Fréchet distance between multivariate normal distributions](https://core.ac.uk/reader/82269844)\" la diestancia de Fréchet entre dos distibuciones gaussianas multivariadas $X$ and $Y$ es:\n",
    "\n",
    "$d(X, Y) = \\Vert\\mu_X-\\mu_Y\\Vert^2 + \\mathrm{Tr}\\left(\\Sigma_X+\\Sigma_Y - 2 \\sqrt{\\Sigma_X \\Sigma_Y}\\right)$\n",
    "\n",
    "\n",
    "Ahora usted deberá implementarla\n",
    "\n",
    "Obs: \n",
    "\n",
    "*   Le podrían ser de utilidad las funciones `torch.norm` y `torch.trace`.\n",
    "*   Se le proporciona una función `matrix_sqrt()` -- usela en vez de `torch.sqrt()` que entrega la raiz cuadrada elemento por elemento. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOlCmNPiuuhK"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def matrix_sqrt(x):\n",
    "    y = x.cpu().detach().numpy()\n",
    "    y = scipy.linalg.sqrtm(y)\n",
    "    return torch.Tensor(y.real, device=x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hLWk57s91it"
   },
   "outputs": [],
   "source": [
    "def frechet_distance(mu_x, mu_y, sigma_x, sigma_y):\n",
    "    ### YOUR CODE HERE ###\n",
    "    fd = None\n",
    "    #### START CODE HERE ####\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pphv97XEgPDh"
   },
   "outputs": [],
   "source": [
    "# UNIT TESTS\n",
    "\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "mean1 = torch.Tensor([0, 0])\n",
    "covariance1 = torch.Tensor(\n",
    "    [[1, 0],\n",
    "     [0, 1]]\n",
    ")\n",
    "dist1 = MultivariateNormal(mean1, covariance1)\n",
    "\n",
    "mean2 = torch.Tensor([0, 0])\n",
    "covariance2 = torch.Tensor(\n",
    "    [[2, -1],\n",
    "     [-1, 2]]\n",
    ")\n",
    "dist2 = MultivariateNormal(mean2, covariance2)\n",
    "\n",
    "assert torch.isclose(\n",
    "    frechet_distance(\n",
    "        dist1.mean, dist2.mean,\n",
    "        dist1.covariance_matrix, dist2.covariance_matrix\n",
    "    ),\n",
    "    4 - 2 * torch.sqrt(torch.tensor(3.))\n",
    ")\n",
    "\n",
    "assert (frechet_distance(\n",
    "        dist1.mean, dist1.mean,\n",
    "        dist1.covariance_matrix, dist1.covariance_matrix\n",
    "    ).item() == 0)\n",
    "\n",
    "print(\"Well done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9dMgbxGCTno"
   },
   "source": [
    "Para usar la función `frechet_distance`, se proporciona el método `get_covariance` el cual entrega la matriz de covarianza a partir de una lista de features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BEbwlGLiPWJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_covariance(features):\n",
    "    return torch.Tensor(np.cov(features.detach().numpy(), rowvar=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sw5obaXjVv_v"
   },
   "source": [
    "Finalmente, usted utilizará el modelo Inception-v3 pre entrenado para calcular los features en imágenes reales y generadas, para luego obtener la métrica de FID de los dos modelos entrenados con anterioridad. A continuación se entrega un código para hacer el calculo de features sobre los ejemplos reales y generados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQwHSAhrf0hX"
   },
   "outputs": [],
   "source": [
    "fake_features_list = []\n",
    "real_features_list = []\n",
    "\n",
    "gen.eval()\n",
    "n_samples = 512 # The total number of samples\n",
    "n_samples = 5000 # The total number of samples\n",
    "batch_size = 512 # Samples per iteration\n",
    "\n",
    "dataloader = DataLoader(MNIST('.', download=False, transform=transform),\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "\n",
    "def preprocess(img):\n",
    "    img = torch.nn.functional.interpolate(img, size=(299, 299), mode='bilinear', align_corners=False)\n",
    "    img = img.repeat(1,3,1,1)\n",
    "    return img\n",
    "\n",
    "def compute_features(gen):\n",
    "    cur_samples = 0\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            for real_example, _ in tqdm(dataloader, total=n_samples // batch_size):\n",
    "                real_samples = preprocess(real_example)\n",
    "                real_features = inception_model(real_samples.to(device)).detach().to('cpu')\n",
    "                real_features_list.append(real_features)\n",
    "\n",
    "                fake_samples = get_noise(len(real_example), z_dim).to(device)\n",
    "                fake_samples = preprocess(gen(fake_samples))\n",
    "                fake_features = inception_model(fake_samples.to(device)).detach().to('cpu')\n",
    "                fake_features_list.append(fake_features)\n",
    "                cur_samples += len(real_samples)\n",
    "                if cur_samples >= n_samples:\n",
    "                    return real_features_list, fake_features_list\n",
    "                \n",
    "        except:\n",
    "            print(\"Error in loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the desired generator\n",
    "# gen = None\n",
    "fake_features_list, real_features_list = compute_features(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LUrJ_ZEZXkvu"
   },
   "source": [
    "Utilizando el código anterior, calcule el FID de los modelos DCGAN y WGAN-GP. Para esto: \n",
    "*     Junte los features calculados en el bloque anterior en un tensor \n",
    "*     Calcule los estadísticos necesarios\n",
    "*     Utilice la función `frechet_distance` anteriormente implementada, utilizando los estadísticos previamente calculados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmiOuDulqDTC"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "fake_features_all = None\n",
    "real_features_all = None\n",
    "\n",
    "mu_fake = None\n",
    "mu_real = None\n",
    "sigma_fake = None\n",
    "sigma_real = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(frechet_distance(mu_real, mu_fake, sigma_real, sigma_fake).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de las métricas calculadas, responda: \n",
    "1.    Cómo se compara el desempeño de los modelos de DCGAN y WGAN-GP ?  \n",
    "2.    Es posible evidenciar lo representado por las metricas, cualitativamente ? Muestre un ejemplo\n",
    "3.    Sobre la utilización de la métrica FID, qué parte del procedimiento podría ser \"no tan correcto\" para el problema en cuestión ?  \n",
    "\n",
    "<font size=3 color=red> <b>Respuesta: </b></font>     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
